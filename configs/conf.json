{
    "batch_size": 128,
    "dropout_rate": 0.1,
    "embedding_dim": 512,
    "freq_output__train": 1,
    "freq_output__val": 1,
    "lr_multiplier": 0.1,
    "beta_1": 0.9,
    "beta_2": 0.999,
    "eps": 1e-08,
    "min_frequency": 0,
    "num_epochs": 30,
    "num_heads": 8,
    "num_workers": 4,
    "seed_number": 0,
    "pin_memory": true,
    "seq_length": 128,
    "use_amp": true,
    "warmup_steps": 4000,
    "saving_path": "outputs/3",
    "tokenizer_file": "transformer/bpe_tokenizer_37k.json"
}
