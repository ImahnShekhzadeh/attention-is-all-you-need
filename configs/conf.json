{
    "batch_size": 256,
    "dropout_rate": 0.1,
    "embedding_dim": 512,
    "freq_output__train": 1,
    "freq_output__val": 1,
    "learning_rate": 2e-3,
    "min_frequency": 0,
    "num_epochs": 30,
    "num_heads": 8,
    "num_workers": 4,
    "seed_number": 0,
    "pin_memory": true,
    "seq_length": 128,
    "use_amp": true,
    "saving_path": "outputs/3",
    "tokenizer_file": "transformer/bpe_tokenizer_37k.json"
}
